# Backward-Propagation-Neural-Network

This is a code implementation of a three-layer back-propagation neural network.
Gradient descent and Adagrad are implemented in the code to approach the optimal value, and the optimal number of rounds is tested.
